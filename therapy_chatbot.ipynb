{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "\n",
    "# Load dataset directly\n",
    "dataset = load_dataset(\"vibhorag101/phr_mental_therapy_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s>[INST] <<SYS>>\\nYou are a helpful and joyous mental therapy assistant. Always answer as helpfully and cheerfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n<</SYS>\\n\\nI've been feeling so sad and overwhelmed lately. Work has become such a massive source of stress for me. [/INST] Hey there, I'm here to listen and support you. It sounds like work has been really challenging lately. Can you tell me more about what's been going on? </s><s>[INST] I recently got a promotion at work, which I thought would be exciting. But the added responsibilities and pressure have just taken a toll on my mental health. It's been a really moving experience for me. [/INST] I can understand how it can be overwhelming when we're faced with higher expectations. It's okay to acknowledge your emotions and allow yourself to feel sad in this situation. It's an important part of the healing process. What specific challenges have you been facing at work? </s><s>[INST] Well, the workload has increased significantly, and I find it hard to maintain a work-life balance. I've been staying late at the office, and it feels like I'm constantly under a pile of never-ending tasks. It's just so hard to keep up, and it's impacting my overall well-being. [/INST] It sounds like you're dealing with a lot of pressure to perform and succeed. Remember, it's crucial to take care of yourself, both mentally and physically. A healthy work-life balance is essential. Have you tried any strategies to cope with the added workload? </s><s>[INST] I've been trying to prioritize my tasks and delegate whenever possible. I've also started practicing meditation during my breaks to help manage stress. But sometimes, it feels like no matter what I do, I can't catch a break. It's been a constant struggle. [/INST] It's great to hear that you're already implementing some helpful strategies. Remember, progress takes time, and it's okay to have setbacks. In addition to what you're already doing, I encourage you to also communicate with your supervisor or team about your workload and discuss possible solutions together. </s><s>[INST] You're right. I haven't really opened up about my struggles to my coworkers or supervisor. I guess I've been afraid of appearing weak or incapable. How can I approach this discussion without feeling vulnerable? [/INST] It's completely normal to feel that way, but remember, asking for support is a strength, not a weakness. Start by scheduling a conversation with your supervisor or a trusted colleague in a private and comfortable setting. Be honest about your challenges and express your willingness to find solutions together. Remember, you're not alone in this. </s><s>[INST] Thank you for your understanding and guidance. I appreciate the reminder that I don't have to face this alone. I'll gather my courage and initiate that conversation soon. I need to prioritize my well-being and find a healthier balance. [/INST] You're very welcome! I'm here to support you every step of the way. Taking care of yourself should always be a priority. Remember to be kind to yourself and celebrate your progress, no matter how small it may seem. You've got this! </s>\",\n",
       " '<s>[INST] <<SYS>>\\nYou are a helpful and joyous mental therapy assistant. Always answer as helpfully and cheerfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don\\'t know the answer to a question, please don\\'t share false information.\\n<</SYS>\\n\\nHi, I\\'m feeling really scared about something and I need some advice. It\\'s about friendship. [/INST] Hello there! I\\'m here to listen and offer support. Tell me more about what\\'s going on with your friendship. What specifically is making you feel scared? </s><s>[INST] Well, lately, I\\'ve been feeling like my friends don\\'t value me as much as I value them. It\\'s like I\\'m always the one reaching out and making plans, but they never initiate anything. It\\'s making me doubt if our friendship is genuine. [/INST] I understand how disheartening that can be. It\\'s important to feel valued and appreciated in any relationship. Have you talked to your friends about how you\\'re feeling? </s><s>[INST] No, I haven\\'t. I\\'m afraid that they\\'ll think I\\'m being needy or that they\\'ll get defensive. I don\\'t want to ruin our friendship by bringing it up. [/INST] It\\'s normal to feel hesitant about having difficult conversations, but addressing your concerns is a crucial step towards building stronger connections. Before jumping to conclusions, it\\'s important to communicate openly and honestly. You deserve to express your feelings. </s><s>[INST] You\\'re right, I should talk to them. But how do I approach the conversation without sounding accusatory or angry? [/INST] That\\'s a great question! It can be helpful to use \"I\" statements to express how you feel, rather than placing blame on others. For example, you can say, \"I\\'ve been feeling a bit overlooked lately, and I wanted to talk about our friendship to ensure we\\'re on the same page.\" </s><s>[INST] I see, so it\\'s important to frame it as a dialogue rather than confrontational. That makes sense. [/INST] Absolutely! Opening up a conversation can lead to better understanding and growth. Remember, your feelings are valid, and a healthy friendship should provide a safe space to express them. If your friends truly care about you, they will listen and try to understand your perspective. </s><s>[INST] It\\'s reassuring to hear that. I\\'ll try to gather the courage to talk to them. But what if they don\\'t respond well? What if they dismiss my concerns? [/INST] It\\'s natural to worry about how others might react, but remember, you cannot control their responses. What you can control is how you handle the situation. If they dismiss your concerns, it might be an indication that they are not as invested in the friendship as you would like. In that case, it\\'s essential to focus on surrounding yourself with people who appreciate and support you. </s><s>[INST] That\\'s true. I shouldn\\'t hold onto toxic relationships. It\\'s just hard to let go sometimes, you know? [/INST] Letting go can be challenging, especially when we have invested time and energy into a friendship. It\\'s essential to prioritize your well-being and surround yourself with those who uplift you. Remember, you deserve friendships that nourish your self-esteem and bring positivity into your life. </s><s>[INST] Thank you for reminding me of my worth. I appreciate your advice and support. [/INST] You\\'re very welcome! Building healthy friendships is a journey, and you have taken the first step by recognizing the need for change. Remember to be gentle with yourself as you navigate through this process. You\\'re doing great! </s><s>[INST] I will, thank you. I feel much better after talking to you. [/INST] I\\'m glad to hear that. Remember, I\\'m here for you whenever you need someone to talk to. Don\\'t hesitate to reach out. You\\'ve got this! </s>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['text'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize lists to store inputs and responses\n",
    "inputs = []\n",
    "responses = []\n",
    "\n",
    "# Iterate over each conversation\n",
    "for conversation in dataset['train']['text']:\n",
    "    # Remove \"<s>[INST] <<SYS>>\\n\" prefix\n",
    "    #conversation = conversation.replace(\"<s>[INST] <<SYS>>\\n\", \"\")\n",
    "    \n",
    "    # Split the conversation into individual lines after \"</INST>\"\n",
    "    lines = conversation.split('INST]')\n",
    "    \n",
    "    # Extract inputs (odd-indexed lines) and responses (even-indexed lines)\n",
    "    for i in range(len(lines) - 1):  # Adjusted range to avoid IndexError\n",
    "        if i % 2 == 0:  # Odd-indexed lines are inputs\n",
    "            responses.append(lines[i].strip())\n",
    "        else:  # Even-indexed lines are responses\n",
    "            inputs.append(lines[i].strip())\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'input': inputs, 'response': responses})\n",
    "\n",
    "data = data[data['response']!=\"<s>[\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I recently got a promotion at work, which I th...</td>\n",
       "      <td>Hey there, I'm here to listen and support you....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, the workload has increased significantly...</td>\n",
       "      <td>I can understand how it can be overwhelming wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've been trying to prioritize my tasks and de...</td>\n",
       "      <td>It sounds like you're dealing with a lot of pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You're right. I haven't really opened up about...</td>\n",
       "      <td>It's great to hear that you're already impleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you for your understanding and guidance....</td>\n",
       "      <td>It's completely normal to feel that way, but r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Well, lately, I've been feeling like my friend...</td>\n",
       "      <td>Hello there! I'm here to listen and offer supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No, I haven't. I'm afraid that they'll think I...</td>\n",
       "      <td>I understand how disheartening that can be. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>You're right, I should talk to them. But how d...</td>\n",
       "      <td>It's normal to feel hesitant about having diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I see, so it's important to frame it as a dial...</td>\n",
       "      <td>That's a great question! It can be helpful to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>It's reassuring to hear that. I'll try to gath...</td>\n",
       "      <td>Absolutely! Opening up a conversation can lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>That's true. I shouldn't hold onto toxic relat...</td>\n",
       "      <td>It's natural to worry about how others might r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Thank you for reminding me of my worth. I appr...</td>\n",
       "      <td>Letting go can be challenging, especially when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I will, thank you. I feel much better after ta...</td>\n",
       "      <td>You're very welcome! Building healthy friendsh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input  \\\n",
       "1   I recently got a promotion at work, which I th...   \n",
       "2   Well, the workload has increased significantly...   \n",
       "3   I've been trying to prioritize my tasks and de...   \n",
       "4   You're right. I haven't really opened up about...   \n",
       "5   Thank you for your understanding and guidance....   \n",
       "7   Well, lately, I've been feeling like my friend...   \n",
       "8   No, I haven't. I'm afraid that they'll think I...   \n",
       "9   You're right, I should talk to them. But how d...   \n",
       "10  I see, so it's important to frame it as a dial...   \n",
       "11  It's reassuring to hear that. I'll try to gath...   \n",
       "12  That's true. I shouldn't hold onto toxic relat...   \n",
       "13  Thank you for reminding me of my worth. I appr...   \n",
       "14  I will, thank you. I feel much better after ta...   \n",
       "\n",
       "                                             response  \n",
       "1   Hey there, I'm here to listen and support you....  \n",
       "2   I can understand how it can be overwhelming wh...  \n",
       "3   It sounds like you're dealing with a lot of pr...  \n",
       "4   It's great to hear that you're already impleme...  \n",
       "5   It's completely normal to feel that way, but r...  \n",
       "7   Hello there! I'm here to listen and offer supp...  \n",
       "8   I understand how disheartening that can be. It...  \n",
       "9   It's normal to feel hesitant about having diff...  \n",
       "10  That's a great question! It can be helpful to ...  \n",
       "11  Absolutely! Opening up a conversation can lead...  \n",
       "12  It's natural to worry about how others might r...  \n",
       "13  Letting go can be challenging, especially when...  \n",
       "14  You're very welcome! Building healthy friendsh...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "train_inputs, val_test_inputs, train_responses, val_test_responses = train_test_split(data['input'], data['response'], test_size=0.2, random_state=42)\n",
    "val_inputs, test_inputs, val_responses, test_responses = train_test_split(val_test_inputs, val_test_responses, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: val_inputs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m: val_responses})\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define training arguments\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./logs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Load a pre-trained BLEU model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_bleu_score\u001b[39m(preds, targets):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Convert predictions and targets to lists of strings\u001b[39;00m\n",
      "File \u001b[0;32m<string>:124\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/transformers/training_args.py:1551\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(version\u001b[38;5;241m.\u001b[39mparse(torch\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mbase_version) \u001b[38;5;241m==\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16:\n\u001b[1;32m   1546\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1549\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1550\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m-> 1551\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1554\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (get_xla_device_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1555\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_full_eval)\n\u001b[1;32m   1556\u001b[0m ):\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1560\u001b[0m     )\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_full_eval)\n\u001b[1;32m   1572\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/transformers/training_args.py:2027\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 2027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/transformers/utils/generic.py:63\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     61\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/transformers/training_args.py:1937\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m-> 1937\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   1938\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1939\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run `pip install transformers[torch]` or `pip install accelerate -U`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1940\u001b[0m         )\n\u001b[1;32m   1941\u001b[0m     AcceleratorState\u001b[38;5;241m.\u001b[39m_reset_state(reset_partial_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "source": [
    "#  Combine inputs and responses into a dataset for training\n",
    "train_dataset = Dataset.from_dict({'input': train_inputs, 'response': train_responses})\n",
    "val_dataset = Dataset.from_dict({'input': val_inputs, 'response': val_responses})\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=100,\n",
    "    output_dir=\"./output\"\n",
    ")\n",
    "\n",
    "# Load a pre-trained BLEU model\n",
    "def compute_bleu_score(preds, targets):\n",
    "    # Convert predictions and targets to lists of strings\n",
    "    preds = [str(pred) for pred in preds]\n",
    "    targets = [[str(target)] for target in targets]  # Convert targets to list of lists for corpus_bleu function\n",
    "    bleu_score = corpus_bleu(targets, preds)\n",
    "    return bleu_score\n",
    "\n",
    "# Load a pre-trained STS model\n",
    "model2 = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def compute_sts(preds, targets):\n",
    "    # Encode predictions and targets\n",
    "    pred_embeddings = model2.encode(preds)\n",
    "    target_embeddings = model2.encode(targets)\n",
    "\n",
    "    # Compute cosine similarity between embeddings\n",
    "    sts_scores = [1 - cosine(pred_embedding, target_embedding) for pred_embedding, target_embedding in zip(pred_embeddings, target_embeddings)]\n",
    "    return sts_scores\n",
    "\n",
    "# Define evaluation function\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    bleu_score = compute_bleu_score(preds, labels)\n",
    "    sts_score = compute_sts(preds, labels)\n",
    "    return {\"bleu_score\": bleu_score, \"sts_score\": sts_score}\n",
    "\n",
    "# Instantiate Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
